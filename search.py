import os
import argparse
from typing import List, Set, Dict, Any

# å°è¯•å¯¼å…¥ colorama
try:
    import colorama
    from colorama import Fore, Style
    colorama.init(autoreset=True)
    COLOR_DIR = Fore.CYAN
    COLOR_FILE_MATCH = Fore.GREEN
    KEYWORD_COLORS = [Fore.YELLOW, Fore.RED, Fore.BLUE, Fore.CYAN,Fore.MAGENTA]
    STYLE_RESET = Style.RESET_ALL
except ImportError:
    class EmptyColor:
        def __getattr__(self, name): return ""
    Fore = EmptyColor()
    Style = EmptyColor()
    COLOR_DIR, COLOR_FILE_MATCH, STYLE_RESET = "", "", ""
    KEYWORD_COLORS = ["", "", "", "", ""]
    print("[æç¤º] æœªæ‰¾åˆ° 'colorama' åº“,è¾“å‡ºå°†ä¸å¸¦é¢œè‰².å»ºè®®è¿è¡Œ: pip install colorama")

# --- æ–°å¢:åªåœ¨è¿™äº›æ‰©å±•åçš„æ–‡ä»¶ä¸­æœç´¢ ---
# æ‚¨å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šæ–‡æœ¬æˆ–ä»£ç æ–‡ä»¶çš„æ‰©å±•å
TEXT_EXTENSIONS = {
    # çº¯æ–‡æœ¬ & æ–‡æ¡£
    '.txt', '.md', '.rst', '.log', '.csv', '.tsv', '.tex', '.json', '.xml', 
    '.yaml', '.yml', '.toml', '.ini', '.cfg',
    # ç¼–ç¨‹è¯­è¨€
    '.c', '.h', '.cpp', '.hpp', '.cs', '.java', '.py', '.pyw', '.rb', '.go', 
    '.rs', '.swift', '.kt', '.kts', '.scala', '.pl', '.pm', '.sh', '.bash', 
    '.zsh', '.ps1', '.lua',
    # Web å¼€å‘
    '.html', '.htm', '.css', '.scss', '.sass', '.less', '.js', '.mjs', '.cjs', 
    '.ts', '.tsx', '.jsx', '.vue', '.svelte', '.php', '.phtml', '.sql'
}

# é»˜è®¤æ’é™¤çš„ç›®å½•åç§°åˆ—è¡¨
DEFAULT_EXCLUDE_NAMES = {
    '.git', '.idea', '.vscode', 'node_modules', '__pycache__', 'build', 'dist', 'target'
}

def find_keywords_in_file(file_path: str, keywords: List[str], case_insensitive: bool, mode: str) -> Set[str]:
    """æ£€æŸ¥å•ä¸ªæ–‡ä»¶ä¸­æ˜¯å¦åŒ…å«å…³é”®å­—."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
    except (IOError, OSError):
        return set()

    content_to_search = content.lower() if case_insensitive else content
    
    found_keywords = set()
    if mode == 'ANY':
        for keyword in keywords:
            keyword_to_search = keyword.lower() if case_insensitive else keyword
            if keyword_to_search in content_to_search:
                found_keywords.add(keyword)
        return found_keywords
    
    elif mode == 'ALL':
        all_found = True
        for keyword in keywords:
            keyword_to_search = keyword.lower() if case_insensitive else keyword
            if keyword_to_search not in content_to_search:
                all_found = False
                break
        return set(keywords) if all_found else set()

    return set()

def collect_matches(root_dir: str, keywords: List[str], case_insensitive: bool, exclude_names: Set[str], exclude_paths: Set[str], mode: str) -> List[Dict]:
    """ç¬¬ä¸€é˜¶æ®µ:éå†æ–‡ä»¶ç³»ç»Ÿ,åªæ”¶é›†åŒ¹é…é¡¹,ä¸æ‰“å°."""
    matches = []
    for dirpath, dirnames, filenames in os.walk(root_dir, topdown=True):
        dirnames[:] = [d for d in dirnames if d not in exclude_names]
        dirs_to_keep = []
        for d in dirnames:
            if os.path.abspath(os.path.join(dirpath, d)) not in exclude_paths:
                dirs_to_keep.append(d)
        dirnames[:] = dirs_to_keep

        for filename in filenames:
            # --- ä¿®æ”¹:åªæ£€æŸ¥å…·æœ‰æ–‡æœ¬æ‰©å±•åçš„æ–‡ä»¶ ---
            file_ext = os.path.splitext(filename)[1].lower()
            if file_ext in TEXT_EXTENSIONS:
                file_path = os.path.join(dirpath, filename)
                found_keywords = find_keywords_in_file(file_path, keywords, case_insensitive, mode)
                if found_keywords:
                    matches.append({'path': file_path, 'keywords': found_keywords})
    return matches

def build_file_tree(matches: List[Dict], root_dir: str) -> Dict:
    """æ ¹æ®åŒ¹é…åˆ—è¡¨æ„å»ºä¸€ä¸ªåµŒå¥—å­—å…¸æ¥è¡¨ç¤ºæ–‡ä»¶æ ‘."""
    tree = {}
    for match in matches:
        relative_path = os.path.relpath(match['path'], root_dir)
        parts = relative_path.split(os.sep)
        current_level = tree
        for part in parts[:-1]:
            current_level = current_level.setdefault(part, {})
        current_level[parts[-1]] = {'_is_file_': True, 'keywords': match['keywords']}
    return tree

def print_condensed_tree(node: Dict, prefix: str = ""):
    """ç¬¬äºŒé˜¶æ®µ:é€’å½’åœ°æ‰“å°ç”±åŒ¹é…é¡¹æ„æˆçš„ç®€æ´æ–‡ä»¶æ ‘."""
    items = sorted(node.keys())
    for i, item in enumerate(items):
        connector = "â””â”€â”€ " if i == len(items) - 1 else "â”œâ”€â”€ "
        is_file = node[item].get('_is_file_', False)
        
        if is_file:
            colored_keywords = []
            sorted_keywords = sorted(list(node[item]['keywords']))
            for j, keyword in enumerate(sorted_keywords):
                color = KEYWORD_COLORS[j % len(KEYWORD_COLORS)]
                colored_keywords.append(f"{color}{keyword}{STYLE_RESET}")
            keywords_str = ", ".join(colored_keywords)
            print(f"{prefix}{connector}âœ…ï¸ {COLOR_FILE_MATCH}{item}{STYLE_RESET} ({keywords_str})")
        else:
            print(f"{prefix}{connector}{COLOR_DIR}{item}{STYLE_RESET}")
            new_prefix = prefix + ("    " if i == len(items) - 1 else "â”‚   ")
            print_condensed_tree(node[item], new_prefix)

def main():
    parser = argparse.ArgumentParser(
        description="åœ¨æ–‡ä»¶å¤¹ä¸­é€’å½’æœç´¢åŒ…å«ç‰¹å®šå­—ç¬¦ä¸²çš„æ–‡æœ¬æ–‡ä»¶,å¹¶ä»¥æ ‘çŠ¶ç»“æ„æ˜¾ç¤ºç»“æœ.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    # --- ä¿®æ”¹:å°†å…³é”®å­—å‚æ•°åˆ†ä¸ºé»˜è®¤çš„ORæœç´¢å’Œå¯é€‰çš„ANDæœç´¢ ---
    parser.add_argument('keywords', nargs='*', default=[], 
                        help='(é»˜è®¤) æŸ¥æ‰¾å«æœ‰ä»»æ„ä¸€ä¸ªå…³é”®å­—çš„æ–‡ä»¶ (OR æœç´¢).')
    parser.add_argument('-c', '--co-occurrence', nargs='+', 
                        help='æŸ¥æ‰¾åŒæ—¶å«æœ‰æ‰€æœ‰è¿™äº›å…³é”®å­—çš„æ–‡ä»¶ (AND æœç´¢).')

    parser.add_argument('-p', '--path', default='.', help='è¦æœç´¢çš„ç›®å½•è·¯å¾„ (é»˜è®¤ä¸ºå½“å‰ç›®å½•).')
    parser.add_argument('-i', '--case-insensitive', action='store_true', help='è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„æœç´¢.')
    parser.add_argument('-e', '--exclude', action='append', default=[],
                        help='è¦æ’é™¤çš„ç›®å½• (å¯å¤šæ¬¡ä½¿ç”¨).\n- æŒ‰åç§°: --exclude doc\n- æŒ‰è·¯å¾„: --exclude target/classes')
    parser.add_argument('--full-tree', action='store_true', help='æ˜¾ç¤ºå®Œæ•´ç›®å½•æ ‘,è€Œä¸ä»…ä»…æ˜¯åŒ…å«åŒ¹é…é¡¹çš„åˆ†æ”¯.')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†å…³é”®å­—
    if not args.keywords and not args.co_occurrence:
        parser.error("é”™è¯¯: å¿…é¡»æä¾›å…³é”®å­—è¿›è¡Œæœç´¢.è¯·ä½¿ç”¨ 'python search.py å…³é”®å­—...' æˆ– 'python search.py -c å…³é”®å­—...'.")

    # ç¡®å®šæœç´¢æ¨¡å¼å’Œå…³é”®å­—
    if args.co_occurrence:
        search_mode = 'ALL'
        keywords_to_search = args.co_occurrence
    else:
        search_mode = 'ANY'
        keywords_to_search = args.keywords

    search_path = os.path.abspath(args.path)
    if not os.path.isdir(search_path):
        print(f"é”™è¯¯: è·¯å¾„ '{search_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ç›®å½•.")
        return
        
    exclude_names = set(DEFAULT_EXCLUDE_NAMES)
    exclude_paths = set()
    for pattern in args.exclude:
        normalized_pattern = os.path.normpath(pattern)
        if os.sep in normalized_pattern:
            exclude_paths.add(os.path.abspath(os.path.join(search_path, normalized_pattern)))
        else:
            exclude_names.add(normalized_pattern)

    # ç”±äº --full-tree æ¨¡å¼å·²è¢«åºŸå¼ƒ(é€»è¾‘æœªæ›´æ–°),æˆ‘ä»¬åªä½¿ç”¨ç®€æ´æ¨¡å¼
    # å¦‚æœéœ€è¦å®Œæ•´æ¨¡å¼,éœ€è¦å°†æ–‡ä»¶æ‰©å±•åè¿‡æ»¤é€»è¾‘ä¹Ÿæ·»åŠ åˆ° search_and_print_full_tree å‡½æ•°ä¸­
    if args.full_tree:
         print("è­¦å‘Š: --full-tree æ¨¡å¼å½“å‰æœªå®Œå…¨æ”¯æŒæ‰€æœ‰æ–°åŠŸèƒ½,å¯èƒ½æ˜¾ç¤ºä¸å‡†ç¡®.å»ºè®®ä½¿ç”¨é»˜è®¤çš„ç®€æ´è¾“å‡º.")

    matches = collect_matches(search_path, keywords_to_search, args.case_insensitive, exclude_names, exclude_paths, search_mode)
    if not matches:
        print("åœ¨æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…é¡¹.")
        return
        
    print(f"{COLOR_DIR}ğŸ“ {os.path.basename(search_path)}{STYLE_RESET}")
    file_tree = build_file_tree(matches, search_path)
    print_condensed_tree(file_tree)

if __name__ == "__main__":
    main()
